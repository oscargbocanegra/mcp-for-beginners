import asyncio
import traceback
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from llm import interpret_with_gpt

server_params = StdioServerParameters(
    command="python",
    args=["server.py"]  # Ejecuta el servidor del horÃ³scopo
)

async def run():
    try:
        print("ğŸ”® Cliente de HorÃ³scopo conectado al LLM y servidor MCP...")
        async with stdio_client(server_params) as (read, write):
            print("ğŸŸ¢ Servidor MCP conectado. Iniciando sesiÃ³n...")
            async with ClientSession(read, write) as session:
                await session.initialize()

                print("ğŸ’¬ Puedes escribir tu mensaje. Ejemplo: 'Dime el horÃ³scopo de Libra' o 'Â¿QuiÃ©n fue Nikola Tesla?'.")
                print("Escribe 'salir' para terminar.\n")

                while True:
                    user_input = input("ğŸ—£ï¸ TÃº: ")
                    if user_input.lower() in {"salir", "exit", "quit"}:
                        break

                    try:
                        parsed = await interpret_with_gpt(user_input)

                        # Si el modelo indica usar una herramienta
                        if isinstance(parsed, dict) and "tool" in parsed:
                            tool = parsed["tool"]
                            args = parsed.get("arguments", {})
                            print(f"ğŸ”§ Ejecutando {tool} con {args}...")

                            result = await session.call_tool(tool, arguments=args)

                            # Manejo del contenido del servidor MCP
                            final_text = None
                            if hasattr(result, "structuredContent") and isinstance(result.structuredContent, dict):
                                final_text = (
                                    result.structuredContent.get("result")
                                    or result.structuredContent.get("text")
                                    or str(result.structuredContent)
                                )
                            else:
                                final_text = getattr(result, "content", str(result))

                            print("âœ… HorÃ³scopo:", final_text, "\n")

                        # Si es respuesta normal del modelo (chat libre)
                        elif isinstance(parsed, dict) and "response" in parsed:
                            print("ğŸ’¬", parsed["response"], "\n")

                        # Si es texto sin JSON
                        elif isinstance(parsed, str):
                            print("ğŸ’¬", parsed, "\n")

                        else:
                            print("âš ï¸ Respuesta inesperada:", parsed, "\n")

                    except Exception:
                        print("âŒ Error durante la interacciÃ³n:")
                        traceback.print_exc()
                        print()

    except Exception:
        print("âŒ Error general:")
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(run())
